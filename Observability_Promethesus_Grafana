- System(Application + Infrastructure) - App + Networking - Observability.
- State of the application.
- Failures you can understand.
- State of your infrastructure.
- State of Networking.
- Latency.
- Http Traffic.
- Disk utilization of a particular node on my kubernetes cluster over the last 24 hours.
- CPU utilization of a prticular node of the Kubernetes Cluster.
- Memory Utlization.
- Out of 100 Http Requests or out of 100 API calls that are made to the application, How many are successful. What are the number of requests that were failure.
- State of the system like 
i.) Disk Utilization.
ii.) CPU Utlization.
iii.) Memory Utilization.
iv.) Even the number of requests that are failed or passed.

- Observaility doesnt stop there it will also help you understand why is your system in that state, but it will help you understand why its in a particular state.
- Lets say there are 100 http requests, in that why 5 requests are failed what is the reason for it, which part of the applicatin the request is failing what is the reason for it.
- In which part of the application the request is failing you can get the complete information about the faiure and also understand why is there a memory leak by a particular app.
- How to fix 5 http requests that are failing
- So you can get complete traces of this http requests, How the http requests has passed through the load balancer when did it reach the front end application then to the backend 
  and then to the database, where exactly is the http request failing, once you get the information you can fix the particular request same happens with the memory leak as well
  as application is using more amount of memoery using these traces. You can understand which part of the application is using more extensivley and how to fix it.

- Three Pillars of Obsevability
- Metrics
- Logging
- Traces
- If you have set of metrics, logs and traces for your application and you have the application in place for tracking the metrics logging and tracing you have set of observability
  so the metrics part is basically responsible what is the state of the system.
- Logging part is responsible system in the state and traces will help you understand how to fix that particular state.

                                                                    Promethesus Architecture 
                                                          /          /          |            \
                                             Retrieval Time  Alert Manager  Push Gateway   Series Database

- How to configure promethesus as a datsource in grafana..?
- Install Grafana, Setup Grafana, Integrate Grafana.
- Promethesus is for visulization.
- Monitoring system collects the metrics or scrapes the metrics pulls the metrics in the dashboard format it can be any kind of dashboard.
- Setup alerts if the value goes above certain paramateres send a text or notification.
- Pulling the info from metrics showing on dashboards also capable of firing alerts.
- Ex - An app is deployed on kubernetes cluster in AWS env lets say the nodes of the kubernetes clusters are AWS vms there is also AWS networking like VPC to understand the 
  state of entire system not only about the app, but the state of your AWS infratsructure even if this is not right your app will not be stable or your app cannot be up and 
  running 24 hours, there will be some user experience.
- CPU of vms of AWS 
- Historical info of CPU at each time.
- Memoery of AWS vms
- Metrics for kubernetes cluster - like Pod status
- How many times the pod went into the crash back loop off throughout a day and at what time the pod went into crashback loop off or the deployment http requests received by
  your application,(Receieving traffic you can understand http request)
- How many users have signed up in the last request, 
- Either these metrics are fed to the system or monitoring automaticlaly pulls these metrics.

                   -----> Push Mechanism
  Monitoring System Scrapes
                  <------ Pull Mechanism    

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Q - How did you implement Prometheus, Grafana in EKS?
- Prometheus collects metrics.
- Grafana visualizes metrics.
- Helm is used to deploy both in the EKS cluster

Q - How does Prometheus get the server logs? (mechanism of Prometheus)
  - Prometheus is a monitoring tool that collects and stores metrics data.
  - Exporters expose metrics.
  - Prometheus scrapes metrics from exporters.
  - Metrics are stored in a time-series database for querying and visualization

Q - How did you create alerts in Grafana?
  - Define alert rules. 
  - Configure notification channels.
  - Save the alert configuration in the Grafana dashboard.
  - This setup ensures you receive timely notifications based on the metrics you are monitoring.

Q - What is Prometheus, and what makes it useful in DevOps?
  - Prometheus is an open-source systems monitoring and alerting toolkit designed for reliability and scalability. 
  - It works by scraping metrics from targets, storing them in a time-series database, and enabling complex querying and alerting. 
  - Prometheus is particularly useful in DevOps for tracking performance, identifying issues in real-time, and automating alerts, making it easy to maintain application health and
    meet SLAs.

Q - What are the key components of Prometheus?
  - Prometheus consists of several key components:

 - Prometheus Server: Responsible for scraping and storing metrics in a time-series database.
 - Exporters: Small applications that expose metrics in a Prometheus-compatible format.
 - Alertmanager: Handles alerts generated by Prometheus, supporting alert grouping, silencing, and routing.
 - Pushgateway: Allows short-lived jobs to expose metrics.
 - PromQL: A powerful query language used to retrieve and manipulate time-series data.
 - Visualization Tools: Tools like Grafana, which integrate with Prometheus to visualize metrics.”

Q - Explain how Prometheus scrapes data from targets.
  - This question tests your knowledge of the data collection process in Prometheus.
  - “Prometheus scrapes data by periodically querying endpoints on targets that expose metrics in a specific format, typically /metrics endpoints. 
  - It uses a pull-based approach, where Prometheus itself initiates the data collection based on its scrape configurations. 
  - This setup includes specifying scrape intervals, the target endpoints, and any relabeling configurations needed to customize data collection."

Q - What is an exporter in Prometheus? Can you name a few commonly used exporters?
  - Exporters are critical in Prometheus, and this question checks your familiarity with different exporters.
  - “An exporter in Prometheus is a service that collects metrics from a system and exposes them in a format that Prometheus can scrape. Common exporters include:
  - Node Exporter: For Linux system metrics.
  - Blackbox Exporter: For probing endpoints like HTTP, DNS, TCP, and ICMP.
  - MySQL Exporter: For MySQL database metrics.
  - JMX Exporter: For Java applications.
  - Exporters make it easy to monitor diverse systems and applications using Prometheus.”

Q - What is PromQL, and why is it important?  
  - PromQL is a fundamental part of Prometheus, and interviewers may ask about it to assess your ability to retrieve and analyze data.
  - “PromQL, or Prometheus Query Language, is a powerful and flexible language used to query and retrieve metrics from Prometheus’ time-series database. 
  - PromQL allows you to filter, aggregate, and manipulate data to create complex queries for monitoring. 
  - It’s essential for generating detailed insights, visualizations, and alerts, making it one of the core features of Prometheus.”

  - Grafana:
Q - What is Grafana, and how does it complement Prometheus for Kubernetes monitoring?
  - Grafana is an open-source platform for visualizing and analyzing metrics and logs. 
  - It complements Prometheus by providing a user-friendly interface for creating dashboards and exploring metrics collected by Prometheus.

Q - Explain the process of setting up Grafana for Kubernetes monitoring. What steps are involved, and how do you connect it to Prometheus?
  - Setting up Grafana for Kubernetes monitoring involves installing Grafana, configuring a data source with Prometheus as the backend, and creating dashboards to visualize metrics. 
  - You connect Grafana to Prometheus by specifying the Prometheus server URL in the data source configuration.

Q - How can you create dynamic and interactive dashboards in Grafana for monitoring Kubernetes clusters?
  - Grafana supports dynamic dashboards using template variables. 
  - You can create dropdowns and variable queries to allow users to interactively select namespaces, Pods, or other labels for metrics exploration.

Q - Explain how Grafana alerting works in conjunction with Prometheus alerts. How can you set up notifications for critical events in Kubernetes?
  - Grafana can integrate with Prometheus alerts and extend alerting capabilities by providing notification channels. 
  - You can set up alert notifications via email, Slack, or other platforms based on Prometheus alerts triggered by critical events in Kubernetes.

Q - What is Grafana Loki, and how does it enhance Kubernetes log monitoring in conjunction with Prometheus and Grafana?
  - Grafana Loki is a log aggregation system that can be integrated with Prometheus and Grafana. 
  - It enhances Kubernetes log monitoring by allowing you to correlate logs with metrics, perform log queries, and create logs-based dashboards.

Q - Explain the concept of Grafana data sources and how they enable integration with various data providers, including Prometheus.
  - Grafana data sources are plugins that allow Grafana to connect to various data providers, including Prometheus. 
  - By configuring a Prometheus data source, Grafana can retrieve and visualize metrics collected by Prometheus.

 - What are Grafana panels, and how can you use them to create visualizations for Kubernetes monitoring?
 - Grafana panels are individual visual elements within a dashboard. 
 - You can use them to create visualizations such as graphs, tables, and heatmaps to display Kubernetes metrics and monitor cluster health.

 - What are some best practices for designing effective Kubernetes monitoring dashboards in Grafana?
 - Best practices include using clear and descriptive metric names, organizing panels logically, setting appropriate time ranges, using template variables for dynamic dashboards, 
   and creating alerts for critical conditions.

 - How can you ensure the scalability and high availability of Prometheus and Grafana components in a production Kubernetes environment?
 - To ensure scalability and high availability, you can deploy multiple Prometheus instances, use remote write and storage solutions for Prometheus data, and set up Grafana in a 
  highly available configuration with load balancing.

- What are the potential challenges and considerations when configuring Grafana alerts for Kubernetes monitoring, and how can you mitigate them?
- Challenges include defining alert thresholds, reducing false positives, and handling alerting for multi-tenant clusters. 
- Mitigations include setting appropriate alerting rules.

Q - Prometheus:
  - Explain the role of “Prometheus exporters” in Kubernetes monitoring. Can you provide examples of commonly used exporters for Kubernetes?
  - Prometheus exporters are specialized components that expose metrics in a format Prometheus can scrape. 
  - Commonly used Kubernetes exporters include `node_exporter` for node-level metrics, `kube-state-metrics` for cluster state information, and `kubelet` for per-Pod metrics.

Q - What are “Histograms” and “Summaries” in Prometheus, and how can they be used to monitor latency and response time in Kubernetes applications?
  - Histograms and Summaries are metric types in Prometheus used for observing distributions of values, such as request latencies. They can help monitor and visualize latency and response time distributions in Kubernetes applications.
  - Grafana:
  - Explain how you can create templated dashboards in Grafana to monitor multiple Kubernetes namespaces or clusters with a single dashboard configuration. Provide an example.
  - Templated dashboards in Grafana allow you to dynamically switch between namespaces or clusters. Here’s an example using a variable for selecting namespaces:

  - yaml
  - SELECT distinct(“namespace”) FROM “k8s_container_memory_usage_bytes”

Q - What are “Grafana annotations,” and how can they be used to provide additional context in Kubernetes monitoring dashboards?
  - Grafana annotations are notes or markers that you can place on a dashboard to provide context for specific events or incidents. 
  - They are useful for adding explanatory information to your Kubernetes monitoring dashboards.
  
- Alerting and Automation:
Q - Explain how you can use Prometheus Alertmanager for managing and routing alerts in Kubernetes monitoring. What is its role in the alerting pipeline?
  - Prometheus Alertmanager is responsible for handling and routing alerts generated by Prometheus. 
  - It allows you to configure notification channels, silence alerts, and group related alerts for better alert management in Kubernetes monitoring.

Q - Describe the process of setting up alerting notifications in Grafana for critical Kubernetes events. 
  - What notification channels can you configure, and how do you ensure reliable alerting?
  - In Grafana, you can set up alerting notifications for critical Kubernetes events using channels such as email, Slack, or custom webhooks. 
  - To ensure reliable alerting, consider configuring multiple notification channels and defining appropriate routing rules in the Alertmanager.

  - Scalability and Optimization:
Q - What strategies can you implement to optimize the storage and query performance of Prometheus in a Kubernetes environment with a large number of metrics?
  - Strategies include setting appropriate retention periods, using downsampling, implementing efficient storage backends, and leveraging remote write and read solutions like 
    Thanos or Cortex.

  - Set Retention Period
  - What: Decide how long to keep the data.
  - Why: Older data takes up more space and slows down queries.
  - How: Set --storage.tsdb.retention.time=15d (for example) in Prometheus config.

Q - Use Downsampling
  - What: Store summary data (like 1-hour averages) instead of every raw metric.
  - Why: Reduces data size and improves query speed.
  - Tool: Use Thanos/Cortex for automatic downsampling.

Q - Use Efficient Storage Backends
  - What: Use block storage or object storage instead of just local disk.
  - Why: Scales better and improves reliability.

  - Examples: Amazon S3, GCS, Azure Blob (via Thanos/Cortex).
Q - Enable Remote Write/Read
  - What: Push metrics to long-term storage systems like Thanos or Cortex.
  - Why: Keeps Prometheus light, while offloading old or heavy data to more powerful systems.

Q - Explain the concept of “Federation” in Prometheus and how it can be used for monitoring multi-cluster or multi-datacenter Kubernetes environments.
  - Federation in Prometheus allows you to collect metrics from multiple Prometheus servers and aggregate them into a central Prometheus instance. 
  - It’s useful for monitoring multi-cluster or multi-datacenter Kubernetes environments.

  - Integration with Other Tools:
Q - How can you integrate Prometheus and Grafana with logging solutions like Elasticsearch and Fluentd to gain a holistic view of Kubernetes applications?
  - Integrating Prometheus and Grafana with logging solutions involves configuring data sources and creating dashboards that combine metrics and logs. 
  - Fluentd can be used for log collection and forwarding to Elasticsearch for indexing and searching.

Q - Explain how you can use Grafana’s “Alert Templating” feature to create dynamic alert notifications based on Prometheus alerts. Provide an example use case.
  - Grafana’s “Alert Templating” allows you to customize alert notifications dynamically based on alert labels or annotations. 
  - For example, you can include specific event details or contact information in alert notifications based on the Kubernetes namespace where the alert originated.
