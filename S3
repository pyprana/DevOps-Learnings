Structure of S3
S3
 └── Bucket (Top-level container)
 └── Folder (Logical, like directories)
 └── Object (Files: data + metadata + key)

Key Components
- Component Description
- Bucket - Global namespace, stores all objects. Unique across AWS.
- Object - Actual data stored (file + metadata).
- Key - Unique identifier for each object in a bucket (acts like a path).
- Prefix - Path-like structure in key name (folder/file.txt).
- Version - Optional; stores multiple versions if versioning is enabled.
- Storage Class - Defines access frequency/cost (e.g., Standard, Glacier).

- Example
- Bucket: my-project-bucket
- Object Key: logs/2025/may/report.csv
- Full path: s3://my-project-bucket/logs/2025/may/report.csv


S3 Lifecycle:
- S3 Lifecycle is a set of rules to automatically move objects between storage classes or delete them after a certain period.
- To save costs by transitioning old or infrequently accessed data to cheaper storage or deleting unnecessary data.
- Use when you have data that becomes less valuable over time, like logs, backups, or archives.
- Applied at the bucket level or prefix level in Amazon S3.

- Example:
- Move files to S3 Glacier after 30 days.
- Delete files after 365 days.

- Key Actions:
- Transition: Move to another storage class (e.g., Standard → Glacier).
- Expiration: Permanently delete objects.

Unlocking S3 Scenarios – 

- Static Website Hosting:
- Host HTML content via S3 by enabling static site hosting and making the bucket public.

- Prevent Accidental Deletion:
- Use versioning + MFA delete to safeguard important data.

- Cost Optimization:
- Move cold data to Glacier using Lifecycle Rules or Intelligent-Tiering.

- Cross-Account Access:
 - Grant access using bucket policies or IAM roles across AWS accounts.

- Data Compliance:
- Use Object Lock (compliance mode) to retain data for 7 years.

- Cross-Region Replication:
- Use CRR with versioning to auto-copy data across AWS regions.

- Secure File Upload from Web App:
- Use pre-signed URLs for controlled client uploads.

- Enable Access Logs:
- Activate server access logging for auditing.

- Data Encryption:
- Use SSE-S3, SSE-KMS, or SSE-C to encrypt data at rest.
- When to Use
- SSE-S3 → Simple, default use case (logs, backups).
- SSE-KMS → When you need control/audit (compliance, finance, healthcare).
- SSE-C → For full key control, highly regulated/custom environments.

- Multipart Uploads:
- For large files (e.g. 10 GB), split and upload parts in parallel.

- Access Denied Errors:
- Check IAM + bucket policies and Block Public Access settings.

- Query Files Without Download:
- Use S3 Select or Athena to run SQL directly on S3 data.

- Auto Delete Old Files:
- Set lifecycle rules to delete files older than 90 days.

- Archive to Glacier:
- Automatically transition unused files to Glacier/Deep Archive.

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Amazon S3 in a production environment, follow these key steps:

✅ 1. Create S3 Bucket
- aws s3api create-bucket --bucket my-prod-bucket --region us-east-1
- Use naming conventions (prod-appname-logs, prod-static-assets)

- Choose region close to your users

✅ 2. Set Bucket Policies (Security)
- Use IAM roles & policies (not public access)

- Block public access:

json
"BlockPublicAcls": true,
"IgnorePublicAcls": true
Bucket policy for limited access:

json
{
  "Version": "2012-10-17",
  "Statement": [{
    "Effect": "Allow",
    "Principal": {"AWS": "arn:aws:iam::123456789012:role/S3AccessRole"},
    "Action": "s3:GetObject",
    "Resource": "arn:aws:s3:::my-prod-bucket/*"
  }]
}

✅ 3. Enable Versioning & Encryption
- aws s3api put-bucket-versioning --bucket my-prod-bucket --versioning-configuration Status=Enabled
- Enable SSE-S3 or SSE-KMS encryption.

✅ 4. Enable Logging (Optional)
aws s3api put-bucket-logging --bucket my-prod-bucket \
--bucket-logging-status '{
  "LoggingEnabled": {
    "TargetBucket": "my-logs-bucket",
    "TargetPrefix": "prod/"
  }
}'

✅ 5. Lifecycle Policies (Data Retention)
Example: Delete logs after 90 days

json
"Rules": [{
  "ID": "DeleteOldLogs",
  "Status": "Enabled",
  "Prefix": "logs/",
  "Expiration": {"Days": 90}
}]

✅ 6. Access from Application
- Use SDK (Python Boto3, Java, Node.js)

- Use IAM roles if EC2/Lambda accessing it

✅ 7. Monitor with CloudWatch
- Enable S3 metrics

- Set alerts for usage, errors, object count
