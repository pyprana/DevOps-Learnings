Structure of S3
S3
 └── Bucket (Top-level container)
 └── Folder (Logical, like directories)
 └── Object (Files: data + metadata + key)

- Key Components
- Component Description
- Bucket - Global namespace, stores all objects. Unique across AWS.
- Object - Actual data stored (file + metadata).
- Key - Unique identifier for each object in a bucket (acts like a path).
- Prefix - Path-like structure in key name (folder/file.txt).
- Version - Optional; stores multiple versions if versioning is enabled.
- Storage Class - Defines access frequency/cost (e.g., Standard, Glacier).

- Example
- Bucket: my-project-bucket
- Object Key: logs/2025/may/report.csv
- Full path: s3://my-project-bucket/logs/2025/may/report.csv

- S3 Lifecycle:
- S3 Lifecycle is a set of rules to automatically move objects between storage classes or delete them after a certain period.
- To save costs by transitioning old or infrequently accessed data to cheaper storage or deleting unnecessary data.
- Use when you have data that becomes less valuable over time, like logs, backups, or archives.
- Applied at the bucket level or prefix level in Amazon S3.

- Example:
- Move files to S3 Glacier after 30 days.
- Delete files after 365 days.

- Key Actions:
- Transition: Move to another storage class (e.g., Standard → Glacier).
- Expiration: Permanently delete objects.

- What is S3?
- Amazon S3 (Simple Storage Service) is an object storage service used to store and retrieve data at any scale. 
- It is highly durable (11 nines), scalable, and accessible from anywhere over the web.

- Key Components
- A bucket is like a root folder that stores your objects. Each bucket name must be globally unique.

- An object is the actual data file stored in S3. Each object has a unique key (its full path), the file content, and metadata.

- Region defines where the bucket physically exists (e.g., us-east-1).

- A prefix simulates folder structures using key names like logs/2024/data.txt.

- Security and Access Control
- S3 uses IAM policies to define who can access which buckets or objects.
- Bucket policies allow access management at the bucket level.
- Access Control Lists (ACLs) are legacy methods for permission control but are still available.
- Block Public Access is used to prevent accidental exposure of data to the public.
- S3 supports encryption with SSE-S3, SSE-KMS, or client-side encryption to protect data at rest.

- Storage Classes
- S3 offers multiple storage classes for cost optimization.
- Standard is for frequent access.
- Infrequent Access (IA) and One Zone-IA are cheaper but for less frequently accessed data.
- Glacier and Glacier Deep Archive are used for long-term archival and are the cheapest.
- You can set lifecycle rules to automatically transition objects between classes or delete them after a certain period.

- Performance Optimization
- Large files can be uploaded using Multipart Upload, which splits files into parts for faster uploads.
- S3 Transfer Acceleration speeds up uploads using AWS edge locations.
- Byte-Range Fetches let you read only specific parts of large files.

6. Monitoring and Logging
- Enable Server Access Logging to record every request made to your bucket.
- Use AWS CloudTrail to track API activity on S3.
- S3 Storage Lens gives usage insights and recommendations.
- You can monitor operations and performance through CloudWatch metrics.

7. Versioning and Replication
- S3 supports versioning, which lets you keep multiple versions of an object to recover from accidental overwrites or deletes.
- MFA Delete adds extra protection by requiring multi-factor authentication to delete objects.
- Cross-Region Replication (CRR) replicates objects to a different region for disaster recovery.
- Same-Region Replication (SRR) keeps a copy in the same region for compliance or backup needs.

8. Advanced Features
- Object Lock allows write-once-read-many (WORM) storage for compliance.
- S3 Select lets you run SQL queries on data within S3 without downloading the entire file.
- Event Notifications can trigger AWS Lambda, SNS, or SQS when objects are added or modified.
- Requester Pays makes the data requester pay for download bandwidth.
- You can also use S3 to host static websites using Static Website Hosting by enabling it in the bucket properties.

9. Use Cases
- S3 is used for backups, static website hosting, log storage, big data analytics, media storage, and application hosting (like storing frontend assets or binaries).

- Unlocking S3 Scenarios – 

- Static Website Hosting:
- Host HTML content via S3 by enabling static site hosting and making the bucket public.

- Prevent Accidental Deletion:
- Use versioning + MFA delete to safeguard important data.

- Cost Optimization:
- Move cold data to Glacier using Lifecycle Rules or Intelligent-Tiering.

- Cross-Account Access:
- Grant access using bucket policies or IAM roles across AWS accounts.

- Data Compliance:
- Use Object Lock (compliance mode) to retain data for 7 years.

- Cross-Region Replication:
- Use CRR with versioning to auto-copy data across AWS regions.

- Secure File Upload from Web App:
- Use pre-signed URLs for controlled client uploads.

- Enable Access Logs:
- Activate server access logging for auditing.

- Data Encryption:
- Use SSE-S3, SSE-KMS, or SSE-C to encrypt data at rest.
- When to Use
- SSE-S3 → Simple, default use case (logs, backups).
- SSE-KMS → When you need control/audit (compliance, finance, healthcare).
- SSE-C → For full key control, highly regulated/custom environments.

- Multipart Uploads:
- For large files (e.g. 10 GB), split and upload parts in parallel.

- Access Denied Errors:
- Check IAM + bucket policies and Block Public Access settings.

- Query Files Without Download:
- Use S3 Select or Athena to run SQL directly on S3 data.

- Auto Delete Old Files:
- Set lifecycle rules to delete files older than 90 days.

- Archive to Glacier:
- Automatically transition unused files to Glacier/Deep Archive.

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

- Generate a report when an Excel file is uploaded to S3 and email it?
- Use S3 Event Notification to trigger a Lambda function.

- Lambda runs the report generator.

- Use SES (Simple Email Service) to email the report.

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

- How did you handle an application or infrastructure migration project?
- Back up and package the application.
- Upload to S3 or use Snowball for large datasets.
- Re-deploy in AWS using EC2, S3, RDS, etc.
- Verify and cut over DNS via Route 53.

- Snowball is an AWS service used to transfer large amounts of data (usually terabytes or petabytes) to or from AWS.

- Instead of uploading huge files over the internet (which is slow), AWS sends you a physical device (called Snowball).
- You copy the data into it, and send it back to AWS. AWS then uploads the data directly into your S3 bucket.

- When to Use:
- Data is too large to upload over the internet.

- Limited bandwidth or slow upload speed.

- Faster and secure bulk migration to the cloud.

- Example:
- You have 100 TB of logs stored in your on-prem server. Uploading it over internet may take weeks. 
- Instead, AWS ships you a Snowball device → you load data → ship back to AWS → data appears in your S3 bucket.

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Q - How can an EC2 instance in a private subnet access an S3 bucket?
A - Use a VPC Gateway Endpoint for S3.
  - It allows the private EC2 to securely connect to S3 without using the internet. It’s cost-effective and recommended over NAT or Transit Gateway.

- NAT Gateway:
- Used to allow instances in a private subnet to access the internet, like downloading software or connecting to S3.

- It only supports outbound traffic. External systems cannot initiate connections to instances behind a NAT.

- It is used within a single VPC.

- Common in scenarios where your EC2s are private, but still need internet access.

- Billing is based on how much data goes out to the internet.

- Transit Gateway:
- Used to connect multiple VPCs together and also link with on-premises networks using VPN or Direct Connect.

- It supports two-way communication (VPC to VPC, VPC to on-prem).

- Works at a regional level and supports scaling across 100s of VPCs.

- Ideal for large enterprise networks that want centralized control and simplified routing.

- Billing depends on the number of attachments and data processed.

- In short:
- Use NAT Gateway when private servers need internet access.

- Use Transit Gateway when you want to connect VPCs or data centers together.

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Q - Any experience in application migration projects?
A - Yes. Uploaded app to S3, used CloudFormation to recreate infra. Also explored AWS Snowball and S3 Glacier for storage.

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Q - How to automate Excel file processing from S3 and send reports?
A - Use S3 Event → triggers Lambda
  - Lambda runs your report script
  - Use SES or SNS to email the report

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Q - How to give time-limited access to a file in S3 to external users?
A - Use pre-signed URLs valid for a specific time (e.g., 3 hours).
  - Amazon S3 in a production environment, follow these key steps:

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Q - How can EC2 access S3 without internet gateway?
A - By using a VPC endpoint for S3. It allows private access to S3 without public internet.

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


✅ 1. Create S3 Bucket
- aws s3api create-bucket --bucket my-prod-bucket --region us-east-1
- Use naming conventions (prod-appname-logs, prod-static-assets)

- Choose region close to your users

✅ 2. Set Bucket Policies (Security)
- Use IAM roles & policies (not public access)

- Block public access:

json
"BlockPublicAcls": true,
"IgnorePublicAcls": true
Bucket policy for limited access:

json
{
  "Version": "2012-10-17",
  "Statement": [{
    "Effect": "Allow",
    "Principal": {"AWS": "arn:aws:iam::123456789012:role/S3AccessRole"},
    "Action": "s3:GetObject",
    "Resource": "arn:aws:s3:::my-prod-bucket/*"
  }]
}

✅ 3. Enable Versioning & Encryption
- aws s3api put-bucket-versioning --bucket my-prod-bucket --versioning-configuration Status=Enabled
- Enable SSE-S3 or SSE-KMS encryption.

✅ 4. Enable Logging (Optional)
aws s3api put-bucket-logging --bucket my-prod-bucket \
--bucket-logging-status '{
  "LoggingEnabled": {
    "TargetBucket": "my-logs-bucket",
    "TargetPrefix": "prod/"
  }
}'

✅ 5. Lifecycle Policies (Data Retention)
Example: Delete logs after 90 days

json
"Rules": [{
  "ID": "DeleteOldLogs",
  "Status": "Enabled",
  "Prefix": "logs/",
  "Expiration": {"Days": 90}
}]

✅ 6. Access from Application
- Use SDK (Python Boto3, Java, Node.js)

- Use IAM roles if EC2/Lambda accessing it

✅ 7. Monitor with CloudWatch
- Enable S3 metrics

- Set alerts for usage, errors, object count
