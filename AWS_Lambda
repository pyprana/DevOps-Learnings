1. What is AWS Lambda?
- What: Serverless compute service to run code in response to events.
- Why: No server management, auto-scaling, pay-per-use.
- When: For event-driven workloads (e.g., S3 uploads, API calls).
- Where: Integrated with AWS services like S3, DynamoDB, API Gateway.
- How: Upload code → define trigger → Lambda runs when event occurs.
- Example: Resize image on S3 upload.
- Use Case: Microservices, automation scripts, real-time file processing.
- (event-driven workloads- Event-driven workload automation adds the capability to perform on-demand workload automation in addition to plan-based job scheduling. 
- It provides the capability to define rules that can trigger on-demand workload automation)
- (An API call, also known as an API request, is a message sent from one application (the client) to another application (the server) to request data or services. 
- It's how applications communicate and exchange information. Essentially, it's a request for the server to perform a specific action or retrieve data. 
- What they do:
- API calls allow one application to interact with another, enabling actions like retrieving data, sending notifications, or executing transactions. 

- How they work:
- An API call is a structured request sent from a client application to a server, specifying the desired action and any necessary parameters. 
- Examples:
- When you log into a social media app or search for flights on an online travel agency, 
- API calls are being made behind the scenes to interact with the respective servers and retrieve the necessary data. 
- Importance:
- API calls are essential for building interconnected applications and services that rely on sharing data and functionality. 
- Security:
- With each API call, there's a conversation to be had around security. 
- In essence, API calls are the communication backbone of modern software applications, enabling them to interact and exchange information seamlessly. 

2. Lambda Execution Model
- Short-lived functions (up to 15 mins)
- Stateless by design
- Cold start vs. warm start behavior

3. Function Configuration
- Memory (128 MB to 10 GB)
- Timeout (max 900 seconds)
- Environment variables
- IAM Role (execution role)

4. Triggers & Event Sources
- S3 (e.g., file upload triggers)
- API Gateway (REST/HTTP endpoints)
- DynamoDB Streams
- SNS / SQS / EventBridge
- CloudWatch Events / Logs
- Step Functions
(Step Functions is a visual workflow service that helps developers use AWS services to build distributed applications, automate processes)
- What It Does?
- It helps you connect and control different AWS services step by step, like a flowchart, without writing long code.

- Use Cases
- Order Processing
- Example: Customer places order → process payment → check stock → ship product.

- Data Cleanup
- Example: Get data from S3 → clean with Lambda → store in database.

- Approval Workflow
- Example: Someone applies for leave → wait for manager approval → send email.

- ML Model Automation
- Example: Train model → check accuracy → deploy to production if good.

- Retry on Failures
- Example: Try task → if it fails, try again after some time.

- Daily Jobs
- Example: Run report every day → send to email.

- Security Response
- Example: Suspicious login → lock account → alert admin.

- IoT Devices
- Example: Read sensor → if temperature is high, turn on AC.

5. Deployment Packages
- ZIP file or container image.
- Supports Python, Node.js, Java, Go, .NET, Ruby.
- Use Layers for shared libraries.

6. Lambda Layers
- Reusable code/libraries (e.g., boto3, numpy).
- Up to 5 layers per function.

7. Versions & Aliases.
- Versions: Immutable snapshots of function code/config.
- Aliases: Pointers to versions (e.g., "prod", "dev").

8. IAM Roles and Permissions
- Execution Role: What Lambda can do (e.g., write to S3).
- Resource Policy: Who can invoke the Lambda.

9. Lambda Destinations
- Define success/failure targets (e.g., SNS, SQS, Lambda)
- Alternative to manual try/catch

10. Concurrency
- Unreserved concurrency: Shared pool.
- Reserved concurrency: Guarantees function concurrency.
- Provisioned concurrency: Pre-warms instances to avoid cold starts.

11. Monitoring & Logging
- Integrated with CloudWatch Logs
- Metrics: Invocations, Duration, Errors, Throttles
- X-Ray: Tracing for debugging

12. Lambda with VPC
- Access RDS, ElastiCache via VPC config
- Needs ENI (adds latency/cold start)

13. Async vs Sync Invocations
- Sync: Wait for response (e.g., API Gateway)
- Async: Fire-and-forget (e.g., S3 trigger)

14. Deployment & CI/CD
- SAM, Serverless Framework, Terraform, CDK
- Blue/Green with aliases
- Canary deployments

15. Best Practices
- Keep function small and single-purpose.
- Use environment variables for config.
- Minimize cold starts (Provisioned concurrency, lightweight deps)
- Avoid long-running processes (use Step Functions if needed)

16. Do we need a load balancer for Lambda?
- No, Lambda handles concurrency automatically. For routing, Route 53 can be used.

17. Can Lambda be used instead of EC2 for Java apps?
- Yes, if the app is small and event-driven. Lambda is serverless, no infra management needed.



-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

- You might have built a serverless API, systems involving microservices, image/video conversion, log analysis, and many more. 

- What services have you integrated with AWS Lambda?
- This is an extension of the previous question. This is not a laundry list of all event sources that can connect to AWS Lambda. 
- You may have used S3, SNS, SQS, Kinesis, DynamoDB, SES, or others. Not all projects will be completely serverless.
- If you've used any non-serverless component along with AWS Lambda, mention those too. For example, you might've used AWS Lambda with RDS. 

- Explain the concept of cold and warm starts in AWS Lambda
- There are 2 reasons for asking this question. 
- They want to know the runtimes that you've used, and they want to know if you know the other runtimes that could cause a cold start.
- Lambda services receive a request to run a lambda function. 
- The service prepares the execution environment by downloading the handler function code and by allocating memory along with other configuration.
- Even though you're not billed for this execution environment preparation time, you'll have to face the delay in invoking your lambda function. 
- This delay is called a "cold start".
- The cold start timing is less significant for TypeScript and Python runtime environments, whereas it's a bit higher for Java or C# runtime environments.

- To improve performance, the lambda service will keep the execution environment for some time. 
- When you receive the request for the same lambda function again during this period, your handler can start executing immediately. 
- This type of invocation is called a "warm start".

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------

- What's the difference between synchronous and asynchronous invocation in AWS Lambda?
- Even though this seems to be straightforward question, this has many implications for your design and error handling.

- In synchronous invocation, the caller will wait for the execution to complete. 
- But in asynchronous invocation, the caller will put the event in an internal queue which will later be processed in the lambda function.

- An important point to note here is that you can't dictate the type of invocation and it depends on the service that you use with AWS Lambda.

- For example, if you're building serverless APIs using API Gateway, it'll be a synchronous invocation. 
- But if you're using S3, it'll be an asynchronous invocation.

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------

- How do you implement error handling and retry logic in Lambda?
- Any component in event driven system that may fail will fail. 
- This depends on the service that you're using with AWS Lambda. Let's discuss this with some examples.
- If you're building a serverless API, it is better to return that error to the calling client (could be a front end app in this case). 
- Then you let your front end logic decide what to display to the user based on the type of the error.
- If you're using Lambda with SQS, it is better to use a Dead Letter Queue so that you know what messages have failed to process. 
- For this same reason, many of the systems that use SNS may use SQS, too.
- In the below code, we're using a dead letter queue. 
- If any message fails to process after a certain number of times (as specified by maxReceiveCount), it's sent to the dead letter queue. 
- This behaviour is specific to lambda when used along with queues.

- Dead Letter Queue (DLQ) in AWS is used to store messages that can't be processed successfully by a service like SQS, SNS, Lambda, or EventBridge after multiple retry attempts.

- What:
A secondary queue where failed messages go after processing errors.

- Why:
To debug, isolate, and prevent faulty messages from blocking normal message processing.

- When:
- When a Lambda function fails consistently.

- When SQS message processing fails after retries.

- When SNS message delivery fails to a subscriber.

- Where:
- Used with:

- Amazon SQS (Standard & FIFO)

- AWS Lambda

- Amazon SNS

- Amazon EventBridge

- Example:
- You have an SQS queue that triggers a Lambda. If the Lambda fails to process a message after 3 tries, it’s moved to the DLQ for analysis.

