1. What is AWS Lambda?
- What: Serverless compute service to run code in response to events.
- Why: No server management, auto-scaling, pay-per-use.
- When: For event-driven workloads (e.g., S3 uploads, API calls).
- Where: Integrated with AWS services like S3, DynamoDB, API Gateway.
- How: Upload code → define trigger → Lambda runs when event occurs.
- Example: Resize image on S3 upload.
- Use Case: Microservices, automation scripts, real-time file processing.
(event-driven workloads- Event-driven workload automation adds the capability to perform on-demand workload automation in addition to plan-based job scheduling. 
It provides the capability to define rules that can trigger on-demand workload automation)

2. Lambda Execution Model
- Short-lived functions (up to 15 mins)
- Stateless by design
- Cold start vs. warm start behavior

3. Function Configuration
- Memory (128 MB to 10 GB)
- Timeout (max 900 seconds)
- Environment variables
- IAM Role (execution role)

4. Triggers & Event Sources
- S3 (e.g., file upload triggers)
- API Gateway (REST/HTTP endpoints)
- DynamoDB Streams
- SNS / SQS / EventBridge
- CloudWatch Events / Logs
- Step Functions
(Step Functions is a visual workflow service that helps developers use AWS services to build distributed applications, automate processes)

5. Deployment Packages
- ZIP file or container image.
- Supports Python, Node.js, Java, Go, .NET, Ruby.
- Use Layers for shared libraries.

6. Lambda Layers
- Reusable code/libraries (e.g., boto3, numpy).
- Up to 5 layers per function.

7. Versions & Aliases.
- Versions: Immutable snapshots of function code/config.
- Aliases: Pointers to versions (e.g., "prod", "dev").

8. IAM Roles and Permissions
- Execution Role: What Lambda can do (e.g., write to S3).
- Resource Policy: Who can invoke the Lambda.

9. Lambda Destinations
- Define success/failure targets (e.g., SNS, SQS, Lambda)
- Alternative to manual try/catch

10. Concurrency
- Unreserved concurrency: Shared pool.
- Reserved concurrency: Guarantees function concurrency.
- Provisioned concurrency: Pre-warms instances to avoid cold starts.

11. Monitoring & Logging
- Integrated with CloudWatch Logs
- Metrics: Invocations, Duration, Errors, Throttles
- X-Ray: Tracing for debugging

12. Lambda with VPC
- Access RDS, ElastiCache via VPC config
- Needs ENI (adds latency/cold start)

13. Async vs Sync Invocations
- Sync: Wait for response (e.g., API Gateway)
- Async: Fire-and-forget (e.g., S3 trigger)

14. Deployment & CI/CD
- SAM, Serverless Framework, Terraform, CDK
- Blue/Green with aliases
- Canary deployments

15. Best Practices
- Keep function small and single-purpose.
- Use environment variables for config.
- Minimize cold starts (Provisioned concurrency, lightweight deps)
- Avoid long-running processes (use Step Functions if needed)

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

- You might have built a serverless API, systems involving microservices, image/video conversion, log analysis, and many more. 

- What services have you integrated with AWS Lambda?
- This is an extension of the previous question. This is not a laundry list of all event sources that can connect to AWS Lambda. 
- You may have used S3, SNS, SQS, Kinesis, DynamoDB, SES, or others. Not all projects will be completely serverless.
- If you've used any non-serverless component along with AWS Lambda, mention those too. For example, you might've used AWS Lambda with RDS. 

- Explain the concept of cold and warm starts in AWS Lambda
- There are 2 reasons for asking this question. 
- They want to know the runtimes that you've used, and they want to know if you know the other runtimes that could cause a cold start.
- Lambda services receive a request to run a lambda function. 
- The service prepares the execution environment by downloading the handler function code and by allocating memory along with other configuration.
- Even though you're not billed for this execution environment preparation time, you'll have to face the delay in invoking your lambda function. 
- This delay is called a "cold start".
- The cold start timing is less significant for TypeScript and Python runtime environments, whereas it's a bit higher for Java or C# runtime environments.

- To improve performance, the lambda service will keep the execution environment for some time. 
- When you receive the request for the same lambda function again during this period, your handler can start executing immediately. 
- This type of invocation is called a "warm start".

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------

- What's the difference between synchronous and asynchronous invocation in AWS Lambda?
- Even though this seems to be straightforward question, this has many implications for your design and error handling.

- In synchronous invocation, the caller will wait for the execution to complete. 
- But in asynchronous invocation, the caller will put the event in an internal queue which will later be processed in the lambda function.

- An important point to note here is that you can't dictate the type of invocation and it depends on the service that you use with AWS Lambda.

- For example, if you're building serverless APIs using API Gateway, it'll be a synchronous invocation. 
- But if you're using S3, it'll be an asynchronous invocation.

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------

- How do you implement error handling and retry logic in Lambda?
- Any component in event driven system that may fail will fail. So interviewer wants to know how you've handled the error and how you retried in your previous projects. Below are some examples. Always explain with concrete examples.

This depends on the service that you're using with AWS Lambda. Let's discuss this with some examples.

If you're building a serverless API, it is better to return that error to the calling client (could be a front end app in this case). Then you let your front end logic decide what to display to the user based on the type of the error.

If you're using Lambda with SQS, it is better to use a Dead Letter Queue so that you know what messages have failed to process. For this same reason, many of the systems that use SNS may use SQS, too.

In the below code, we're using a dead letter queue. If any message fails to process after a certain number of times (as specified by maxReceiveCount), it's sent to the dead letter queue. This behaviour is specific to lambda when used along with queues.

