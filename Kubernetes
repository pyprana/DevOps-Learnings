Kubernetes

Q - Where are Kubernetes volumes stored?
A - They are stored based on the StorageClass (e.g., EBS, NFS, hostPath).
  - A PersistentVolumeClaim (PVC) binds to a PersistentVolume (PV), which points to actual storage.
  - It exists outside the pod lifecycle, ensuring data isn‚Äôt lost when the pod restarts.

| Storage Type | What is it?                      | Use Case                                    | Persistent Across Pods | Persistent Across Nodes   | Managed by Kubernetes  |
|--------------|----------------------------------|---------------------------------------------|-------------------------|--------------------------|------------------------|
| EBS          | AWS Elastic Block Store          | Cloud block storage for EC2 & Kubernetes    | ‚úÖ Yes                  | ‚ùå No (AZ-specific)       | ‚úÖ Yes (via PVC)       |
| NFS          | Network File System              | Shared storage between multiple pods/nodes  | ‚úÖ Yes                  | ‚úÖ Yes                    | ‚úÖ Yes (external setup)|
| hostPath     | Host node directory mount        | Testing, single-node clusters               | ‚úÖ Yes (on same node)   | ‚ùå No                     | ‚ùå No                  |


Q - How is networking handled in Kubernetes?
A - Kubernetes has no built-in network layer like Docker. Network policies and CNI plugins are used to manage traffic between pods.

Q - Did you automate Kubernetes deployments?
A - Yes, using Helm charts to package and deploy apps across namespaces in Kubernetes clusters.

Q - How you manage secrets and variables in Kubernetes?
A - Secrets: Store and manage sensitive data securely.
  - ConfigMaps: Store and manage non-sensitive configuration data.
  - Both can be used in pods as volumes or environment variables for secure and efficient configuration management.

Q - How to troubleshoot issues when pod failed?
A - Check Pod Status: Use the command kubectl get pods to check the status of the pod.
  - Describe Pod: Use kubectl describe pod <pod-name> to get detailed information about the pod, including events and error messages.
  - View Logs: Use kubectl logs <pod-name> to view the logs of the pod's containers for error messages.
  - Check Events: Use kubectl get events to check for cluster-wide events that might affect the pod.
  - Inspect YAML: Review the pod's YAML configuration for any misconfigurations.

Q - How Kubernetes handle network communication between containers..?
A - Kubernetes uses a flat, cluster-wide network let all the pods communicate directly.
  - To ensure seamless communication between containers, services and external systems.
  - Used when pods need to talk to each other across namespaces or nodes.
  - Handled via CNI(Container Network Interface) plugins. E.,(Calico, Flannel, Cilum).
  - Examples - Pod-to-Pod:curl<pod-ip>
  - Pod-to-Service: curl
  - http://service-name>
  - Across Nodes : CNI ensures routing between pods on different nodes.

Q - What‚Äôs the difference between ClusterIP, NodePort, and LoadBalancer in Kubernetes?
A - ClusterIP: Default type, only accessible within the cluster.
  - NodePort: Opens a port on each node to access from outside (not secure for production).
  - LoadBalancer: Exposes the service externally using a cloud provider‚Äôs load balancer.

Q - What does 'cordon' mean in Kubernetes?
A - It marks a node as unschedulable ‚Äî no new pods will run there, but existing pods stay. Used for maintenance.

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Q - When do you use a Transit Gateway?
A - Use a Transit Gateway to connect multiple VPCs or on-premises networks in a hub-and-spoke model.
  - It‚Äôs best when you have 3 or more VPCs or hybrid cloud setup.

- The hub-and-spoke model is a network architecture where:
- The hub is the central point (like a Transit Gateway).
- The spokes are VPCs or on-prem networks that connect to the hub.
- All communication flows through the hub, not directly between spokes.

- Example:
- Imagine Transit Gateway as an airport hub.
- VPCs are like cities connected to that hub.
- If VPC-A wants to talk to VPC-B, the traffic goes:
- ‚Üí VPC-A ‚Üí Transit Gateway ‚Üí VPC-B

- Benefits:
- Simplifies routing.

- Scales better than full mesh (no need for every VPC to peer with every other).

- Centralizes control, monitoring, and security.

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Q - How have you used PVCs in Kubernetes?
A - I attached Persistent Volume Claims (PVCs) to stateful apps like databases. I created alerts to monitor storage usage and prevent outages.

Q - Difference between PVC and PV in Kubernetes:
  - Persistent Volume (PV)	
  - What	      - Actual storage resource in the cluster	
  - Created By	- Cluster Admin (via PersistentVolume YAML)	
  - Purpose	    - Provides the physical storage	
  - Lifecycle	  - Independent, exists until deleted manually	
  - Binding	    - Waits to be bound by a matching PVC	
  - Example     - Use	Define NFS/EBS/GCE disk storage	

  - Persistent Volume Claim (PVC)
  - What       - Request for storage by a user
  - Created By - Developer/User (via PersistentVolumeClaim YAML)
  - Purpose    - Claims or binds to a suitable PV
  - Lifecycle  - Exists until the pod or claim is deleted
  - Binding    - Binds to an available matching PV
  - Example    - App needs 5Gi storage with ReadWriteOnce

  - Diagram:
  - User --> PVC --> matches criteria --> PV --> underlying storage (EBS/NFS etc.)

  - Summary:

  - PV = What is available

  - PVC = What is needed

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

 - Port Forwarding allows external devices to access services on a private network by mapping an external port to an internal IP and port.

- What:
- Redirects traffic from one IP:port to another IP:port.

- Why:
- To allow access to services (like web servers, SSH, games) running on private IPs behind a router/firewall.

- When:
- Used when you want to expose a local service to the outside world.

- Where:
- Home/Office routers

- Firewalls

- Kubernetes (kubectl port-forward)

- Example: Linux
bash
- # Forward external port 8080 to internal 192.168.1.10:80
- iptables -t nat -A PREROUTING -p tcp --dport 8080 -j DNAT \
  --to-destination 192.168.1.10:80
- Example: Kubernetes
- bash
- kubectl port-forward pod/my-app 8080:80
- Access your pod's port 80 via localhost:8080.

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Q - What is a Kubernetes 'taint'?
A -  A taint blocks pods from scheduling on a node unless they tolerate that taint. Useful for dedicated workloads (e.g., GPU nodes).
  -  A taint is a rule you apply to a node to say:

  - ‚ÄúOnly special pods that can handle this condition are allowed to run here.‚Äù

  - It repels all pods by default unless the pod has a matching toleration.

  -  What is a toleration?
  - A toleration is a permission in the pod spec that says:
  
  - ‚ÄúI‚Äôm okay to run on nodes with this taint.‚Äù
 
  - Why use it?
  - To reserve certain nodes for specific workloads (e.g., GPU, high-memory, licensed apps).

  - Example Use Case:
  - You have GPU nodes in your cluster.

  - You don't want regular apps to run there.

  - You taint the GPU nodes:

  - yaml
  - kubectl taint nodes gpu-node key=gpu:NoSchedule
  - Only ML or AI pods with this toleration can be scheduled:

- yaml
tolerations:
- key: "gpu"
  operator: "Equal"
  value: "true"
  effect: "NoSchedule"

- Diagram:
csharp

[Node A - tainted: gpu=true:NoSchedule]
       ‚¨á
[Pod without toleration] ‚ùå Rejected
[Pod with toleration] ‚úÖ Scheduled

- What is a CSI Secret Store Driver?
- It‚Äôs a way to safely give passwords, tokens, or keys to your app running in Kubernetes, without writing them directly in your YAML files.

- What does it do?
- Instead of storing secrets inside Kubernetes, you can:

- Store secrets in AWS Secrets Manager or Vault (safe and encrypted).

- Use a CSI driver to pull those secrets and give them to your app when it runs.

- How it works:
- You create a pod that needs a secret (like a DB password).

- The CSI driver fetches the secret from AWS Secrets Manager or Vault.

- The secret is given to your pod as a file (not hardcoded).

- Your app reads the file to use the password.

- Two Common Tools:
- AWS Secrets Manager CSI Driver:
- Gets secrets from AWS Secrets Manager and mounts them in the pod.

- Vault Agent Injector (from HashiCorp):
- Runs a helper inside your pod to fetch secrets from Vault and share them with your app.

- Why use it?
- Keeps secrets safe and outside Kubernetes.

- Automatically rotates secrets when changed.

- Avoids hardcoding passwords in configs.

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

- GPU Nodes in Simple Terms:
- GPU nodes in Kubernetes (or any cloud environment) are special worker nodes that have Graphics Processing Units (GPUs).

- Why Use GPU Nodes?
- They‚Äôre used for apps that need high-performance computing, like:

- Machine Learning (ML) / AI model training

- Video rendering

- Scientific simulations

- What Makes GPU Nodes Special?
- Have GPU hardware (like NVIDIA Tesla, A100)

- Run workloads that require parallel processing

- Require specific drivers and runtime (like NVIDIA Docker runtime)

- In Kubernetes:
- You label GPU nodes (e.g., nvidia.com/gpu: 1)

- Use resource requests in pod YAML:

yaml
resources:
  limits:
    nvidia.com/gpu: 1
- Kubernetes will schedule this pod only on GPU nodes

üîê Optional: Use taints and tolerations to ensure only GPU workloads run on GPU nodes.

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Q - I want to update the secrets Without restarting app?
A - By default, secrets mounted as environment variables or through volume mounts won't reflect changes unless the pod is restarted. 
  - To avoid restarts:
  - Use CSI Secret Store Drivers like AWS Secrets Manager CSI Driver or HashiCorp Vault Agent Injector. 
  - These allow secrets to be dynamically fetched and updated in the mounted file system.
  - Your application must be designed to either:
  - Read the secret from the file each time it's needed.
  - Watch the file for changes and reload the configuration.

Q - How do ¬•ou do the node maintenance in kubernetes
  - Node maintenance in Kubernetes is done to update, patch, or reboot a node without disrupting workloads. Here's how you do it step-by-step:
  - Steps to Perform Node Maintenance:
  - Cordon the Node (mark unschedulable):

- kubectl cordon <node-name>
- Prevents new pods from being scheduled on the node.
- Drain the Node (evict pods):
- kubectl drain <node-name> --ignore-daemonsets --delete-emptydir-data
- Safely evicts all pods (except DaemonSets and mirror pods).
- Perform Maintenance:
- OS patching
- Kernel upgrade
- Hardware updates
- Reboot, etc.
- Uncordon the Node (make schedulable):
- kubectl uncordon <node-name>

‚ö†Ô∏è Considerations:
- Ensure PodDisruptionBudgets (PDBs) are respected.
- Use --force only if needed (it can cause disruptions).
- Monitor the node status:
- kubectl get nodes

- How do you implement load balancing in Kubernetes?
- For internal apps, I use NodePort. For external traffic, I use AWS Elastic Load Balancer (ELB), configured with proper ports and DNS.

- Kubernetes Deployment
- A Deployment in Kubernetes is used to manage stateless applications. These applications don't need to remember anything about past requests, and all pods behave identically. 
- Deployments provide:

- Dynamic pod names: Pods get autogenerated names like web-7f6dfc4d75-rjzpg.
- Shared identity: All pods behind a service behave the same; there's no unique hostname per pod.
- Ephemeral storage: By default, any data stored in the container is lost when the pod restarts.
- Parallel scaling and updates: Pods are added, removed, or updated simultaneously for quick rollout.
- Rolling updates: Supports fast updates with options like max surge and max unavailable to ensure high availability during deployment.
- Use Deployment when you're running web servers, REST APIs, frontend apps, or batch processors‚Äîanything that doesn‚Äôt store critical local data.

- Kubernetes StatefulSet
- A StatefulSet is designed for stateful applications, where each pod has a unique identity and may need persistent storage. It offers:
- Stable and ordered pod names: Pods are named predictably, like db-0, db-1, db-2.
- Persistent network identity: Each pod gets a stable DNS name via a headless service, which allows consistent communication in clusters (e.g., a Kafka broker always knows the 
  hostname of its peers).
- Persistent storage: Each pod can have its own persistent volume claim that is not shared with others and survives pod restarts.
- Ordered operations: Pods are created, updated, and deleted one by one. This is important for clustered or coordinated systems where startup order matters.
- Controlled updates: Supports partitioned rolling updates, letting you upgrade specific pods while others stay untouched.
- Use StatefulSet when you're running databases (like MySQL, MongoDB), message queues (like Kafka, RabbitMQ), or any clustered, distributed system that requires stable identity 
  and persistent storage.

Q - Liveness Probe in Kubernetes is a health check mechanism used to determine if a container is still running properly.
  - What: A periodic check to verify if the application inside a container is alive.
  - Why: To automatically restart the container if it's stuck or unresponsive.
  - When: Used when your app might hang but still appear "running" (e.g., infinite loop, deadlock).
  - Where: Defined in the pod spec under containers ‚Üí livenessProbe.

- Example (HTTP Check):
- yaml
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
  initialDelaySeconds: 5
  periodSeconds: 10

- Types:
- httpGet: Hits an HTTP endpoint.

- tcpSocket: Checks if a TCP port is open.

- exec: Runs a command inside the container.

Q - security context
  - Security Context in Kubernetes defines privilege and access control settings for Pods or containers.
  - What:
  - A securityContext is a YAML section in a Pod or container spec that sets rules like user ID (UID), group ID (GID), file permissions, and capabilities.
  - Why:
  - It helps improve security posture by limiting the container's access level and reducing risks like privilege escalation or running as root.
  - When:
  - Used when:
  - Enforcing non-root containers.
  - Needing read-only file systems.
  - Restricting Linux capabilities.
  - Enabling SELinux or AppArmor profiles.
  - Where:
  - Defined at two levels:
  - Pod level ‚Äì applies to all containers.
  - Container level ‚Äì overrides pod-level settings for that container.

- Example:
yaml
apiVersion: v1
kind: Pod
metadata:
  name: secure-pod
spec:
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
  containers:
  - name: app
    image: nginx
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true

- Here‚Äôs a line-by-line explanation of the YAML example using securityContext:

- yaml
- apiVersion: v1
- What: API version of the Kubernetes resource.

- Why: Ensures compatibility with the Kubernetes API server.

- yaml
- kind: Pod
- What: Specifies the type of object ‚Äî a Pod in this case.

- yaml
- metadata:
- name: secure-pod
- What: Sets the name of the pod as secure-pod.

- Why: Useful for identification and management.

-yaml
-spec:
  securityContext:
- What: Defines pod-level security settings.

- Why: Enforces user, group, and filesystem-level access control.

- yaml
    runAsUser: 1000
- What: All containers in the pod will run as user ID 1000.

- Why: Helps avoid running as root for better security.

- yaml
    runAsGroup: 3000
- What: Processes run with group ID 3000.

- Why: Controls group-level permissions.

- yaml
    fsGroup: 2000
- What: Files created in mounted volumes will belong to group ID 2000.

- Why: Enables shared access to volumes within a specific group.

- yaml
  containers:
  - name: app
    image: nginx
What: Defines a container named app using the nginx image.

- yaml
    securityContext:
- What: Container-level security context overrides or adds to pod-level.

- yaml
      allowPrivilegeEscalation: false
- What: Prevents processes in the container from gaining more privileges than their parent.

- Why: Stops use of commands like sudo or setuid programs to escalate privileges.

- yaml
      readOnlyRootFilesystem: true
- What: Mounts the container's root filesystem as read-only.

- Why: Prevents tampering with system binaries or logs inside the container.

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Q - Kubeconfig
- Kubeconfig is a configuration file used by kubectl and other Kubernetes tools to authenticate and connect to a Kubernetes cluster.
- Key Points:
- What: YAML file that holds cluster info, user credentials, and context.
- Why: To allow access and management of Kubernetes clusters securely.
- Where: Usually located at ~/.kube/config on your local machine.
- When: Required whenever you interact with a cluster using kubectl.

- Example:
yaml
apiVersion: v1
clusters:
- cluster:
    server: https://<cluster-endpoint>
    certificate-authority: /path/to/ca.crt
  name: my-cluster
contexts:
- context:
    cluster: my-cluster
    user: my-user
  name: my-context
current-context: my-context
users:
- name: my-user
  user:
    token: <authentication-token>


--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

- ~/.kube/config

- ~/.kube/config is the default Kubeconfig file used by kubectl to interact with a Kubernetes cluster.

- Breakdown:
- Key	Description
- ~	Home directory of the current user.
- .kube	Hidden directory storing Kubernetes config files.
- config	Main file that contains cluster, user, and context details.

- Used For:
- Connecting to multiple clusters.
- Switching contexts (dev, prod, staging).
- Authenticating via tokens, certificates, or plugins.

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

- What is the difference between deploying applications on hosts and containers?
- Deploying Applications consist of an architecture that has an operating system. 
- The operating system will have a kernel that holds various libraries installed on the operating system needed for an application.
- Whereas container host refers to the system that runs the containerized processes. 
- This kind is isolated from the other applications; therefore, the applications must have the necessary libraries. 
- The binaries are separated from the rest of the system and cannot infringe any other application.

- Explain the working of the master node in Kubernetes.
- The master node is the node that controls and manages the set of worker nodes. This kind of cluster resembles a cluster in Kubernetes.
- The nodes are responsible for cluster management and the API used to configure and manage the resources within the collection. 
- The master nodes of Kubernetes can run with Kubernetes itself, the asset of dedicated pods.

- What is the role of Kube-apiserver?
- This kind validates and provides configuration data for the API objects.
- It includes pods, services, replication controllers. Also, it provides REST operations and also the frontend of the cluster.
- This frontend cluster state is shared through which all other component interacts.

- What is a node in Kubernetes?
- A node is the smallest fundamental unit of computing hardware. 
- It represents a single machine in a cluster, which could be a physical machine in a data center or a virtual machine from a cloud provider. Each machine can substitute any other machine in a Kubernetes cluster. The master in Kubernetes controls the nodes that have containers

- What does the node status contain?
- The main components of a node status are Address, Condition, Capacity, and Info.

- What process runs on Kubernetes Master Node? 
- The Kube-api server process runs on the master node and serves to scale the deployment of more instances.

- What is the job of the kube-scheduler?
- The kube-scheduler assigns nodes to newly created pods.

- What is a cluster of containers in Kubernetes? 
- A cluster of containers is a set of machine elements that are nodes. Clusters initiate specific routes so that the containers running on the nodes can communicate. 
- In Kubernetes, the container engine (not the server of the Kubernetes API) provides hosting for the API server.

- What are Daemon sets?
- A Daemon set is a set of pods that runs only once on a host. 
- They are used for host layer attributes like a network or for monitoring a network, which you may not need to run on a host more than once.

- What is ‚ÄòHeapster‚Äô in Kubernetes?
- A Heapster is a performance monitoring and metrics collection system for data collected by the Kublet. 
- This aggregator is natively supported and runs like any other pod within a Kubernetes cluster, which allows it to discover and query usage data from all nodes within the cluster.

- Here‚Äôs the difference between JSON and YAML in simple terms:
- JSON (JavaScript Object Notation)
- Data format used widely in APIs and web apps.

- Uses brackets {} and quotes.
- Strict syntax, good for machines.

- Example:
json
{
  "name": "Pranay",
  "age": 32,
  "skills": ["DevOps", "AWS"]
}

- YAML (YAML Ain‚Äôt Markup Language)
- Used for configuration files (e.g., Kubernetes, Ansible, Docker Compose).
- More human-readable, uses indentation and dashes.
- No need for brackets or quotes unless necessary.
- Example:

- yaml
name: Pranay
age: 32
skills:
  - DevOps
  - AWS

- Key Differences:
- YAML is cleaner and easier to read for humans.

- JSON is stricter and better for machines.

- YAML supports comments (#), JSON does not.

- JSON is used in data exchange, YAML in configuration.

- When to use:

- Use JSON for APIs and data.

- Use YAML for writing config files in DevOps, Kubernetes, etc.

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

- Kubernetes supports multiple authentication mechanisms to verify who is making a request to the cluster API server. Here's a short breakdown:
- Authentication Mechanisms in Kubernetes

1.Static Token File
- Simple bearer token file stored on API server.
- Used in development or testing.
- Example: Authorization: Bearer <token>

2.Static Password File
- Username-password pairs in a file.
- Used with basic auth (discouraged in production).

3.X.509 Client Certificates
- TLS client certificates issued by a CA.
- Common for service-to-service or admin authentication.

4.Service Account Tokens
- Automatically mounted into pods.
- Used for in-cluster communication.

5.OIDC (OpenID Connect)
- Integrates with identity providers (e.g., Google, Azure AD).
- Recommended for enterprise SSO use.

6.Webhook Token Authentication
- API server forwards credentials to external service.
- Flexible, for custom auth logic.

7.Authentication Proxy
- Fronts the API server and handles user auth.

Step-by-Step Pod Troubleshooting
1. Check Pod Status
- kubectl get pod <pod-name> -n <namespace>
- Look for status: CrashLoopBackOff, Pending, ImagePullBackOff, etc.

2. Describe the Pod
- kubectl describe pod <pod-name> -n <namespace>
- Check:
- Events (at bottom)
- Scheduling issues (node selectors, taints, resources)
- Liveness/readiness probe failures

3. Check Pod Logs
- kubectl logs <pod-name> -n <namespace>       # For single container
- kubectl logs <pod-name> -c <container-name>   # For multi-container
- Look for:
- Application errors
- Configuration issues (ports, DB, env vars)

4. Check Node Health
- kubectl get nodes
- kubectl describe node <node-name>
- Ensure:
- Node is Ready
- Sufficient CPU/memory

5. Check Events in Namespace
- kubectl get events -n <namespace> --sort-by=.metadata.creationTimestamp
- Find:
- Scheduling errors
- Image pull issues
- Network problems

6. Check for Image Pull Issues
- kubectl describe pod <pod-name>
- Look for:
- ImagePullBackOff
- Wrong image name/tag
- Missing imagePullSecrets

7. Check Resource Limits
- Pod may be evicted or pending due to CPU/Memory limits.
- Use describe to inspect.

8. Check Network/DNS Issues
- kubectl exec -it <pod> -- nslookup <service-name>
- Ensure:
- DNS is resolving
- Network policies aren‚Äôt blocking traffic

9. Check PVC or Volume Mount Issues
- kubectl describe pvc <pvc-name> -n <namespace>
- Look for:
- Pending or Failed status
- StorageClass or access mode mismatches

10. Check Init Containers
- kubectl describe pod <pod-name>
- Ensure init containers completed successfully.

